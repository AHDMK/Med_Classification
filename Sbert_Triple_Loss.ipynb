{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('',delimiter='\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "punctuations = '!\\\"#$%&\\'()*+,-/:;<=>?@[\\]^_`{|}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in doc ]\n",
    "    mytokens = [ word for word in mytokens if word not in punctuations ]\n",
    "    sentence = \" \".join(mytokens)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util\n",
    "from sentence_transformers.datasets import SentenceLabelDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "\n",
    "def single_sentences(data):\n",
    "    data['cleaned'] = data['text'].apply(spacy_tokenizer)\n",
    "    data=data.assign(scombi=\"\")\n",
    "\n",
    "    for c in range(len(data)):\n",
    "        try:\n",
    "            sentence_tok = []\n",
    "            sentence_tok = tokenize.sent_tokenize(data[\"cleaned\"][c])\n",
    "            if sentence_tok[-1].endswith('.'):\n",
    "                sentence_tok =  sentence_tok\n",
    "            else:\n",
    "                sentence_tok[-1] = str(sentence_tok[-1]) + str('.')\n",
    "            data.loc[c, \"scombi\"] = '  '.join(sentence_tok)\n",
    "        except:\n",
    "            print('1')\n",
    "    list_sent = []\n",
    "    list_cat = []\n",
    "    for c in range(len(data)):\n",
    "        token = data.scombi[c].split('  ')\n",
    "        list_sent.extend(token)\n",
    "        list_temp_cat = [data.Category[c]]*len(token)\n",
    "        list_cat.extend(list_temp_cat)\n",
    "        \n",
    "    return list_sent,list_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = single_sentences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_comp = pd.DataFrame(list(zip(P[0],P[1])),columns = ['text','Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_list_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=data['Category'].unique().tolist()\n",
    "nb_classes = len(classes)\n",
    "print(nb_classes)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,type_c in enumerate(classes):\n",
    "   for j,type_t in enumerate(data['Category']):\n",
    "       if type_c == type_t :\n",
    "           data.loc[j,'Category'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "lst = list(range(len(data)))\n",
    "random_list = random.sample(lst,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.assign(split=\"train\")\n",
    "\n",
    "for z in random_list:\n",
    "    data.loc[z,'split'] = 'eval'\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import LoggingHandler, util\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "train_samples=[]\n",
    "dev_samples=[]\n",
    "for i in range(len(data)):\n",
    "    if data['split'][i] == 'train':\n",
    "        train_samples.append(InputExample(texts=[data['text'][i]],label=data['Category'][i]))\n",
    "    else:\n",
    "        dev_samples.append(InputExample(texts=[data['text'][i]],label=data['Category'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplets_from_labeled_dataset(input_examples):\n",
    "    # Create triplets for a [(label, sentence), (label, sentence)...] dataset\n",
    "    # by using each example as an anchor and selecting randomly a\n",
    "    # positive instance with the same label and a negative instance with a different label\n",
    "    triplets = []\n",
    "    label2sentence = defaultdict(list)\n",
    "    for inp_example in input_examples:\n",
    "        label2sentence[inp_example.label].append(inp_example)\n",
    "\n",
    "    for inp_example in input_examples:\n",
    "        anchor = inp_example\n",
    "\n",
    "        if len(label2sentence[inp_example.label]) < 2:  # We need at least 2 examples per label to create a triplet\n",
    "            continue\n",
    "\n",
    "        positive = None\n",
    "        while positive is None or positive.guid == anchor.guid:\n",
    "            positive = random.choice(label2sentence[inp_example.label])\n",
    "\n",
    "        negative = None\n",
    "        while negative is None or negative.label == anchor.label:\n",
    "            negative = random.choice(input_examples)\n",
    "\n",
    "        triplets.append(InputExample(texts=[anchor.texts[0], positive.texts[0], negative.texts[0]]))\n",
    "\n",
    "    return triplets\n",
    "random.seed(42) \n",
    "dev_triplets = triplets_from_labeled_dataset(dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data_sampler = SentenceLabelDataset(train_samples)\n",
    "train_dataloader = DataLoader(train_data_sampler, batch_size=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_evaluator = TripletEvaluator.from_input_examples(dev_set, name=\"medical_eval\")\n",
    "logging.info(\"Performance before fine-tuning:\")\n",
    "dev_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=16\n",
    "loader = DataLoader(train_samples,batch_size,shuffle=True)\n",
    "#evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "#bert_bio = models.Transformer('dmis-lab/biobert-v1.1')\n",
    "#pooler = models.Pooling(bert_bio.get_word_embedding_dimension(),pooling_mode_mean_tokens = True)\n",
    "#model = SentenceTransformer(modules=[bert_bio, pooler])\n",
    "\n",
    "model= SentenceTransformer('all-MiniLM-L6-v2',device='cuda')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "loss = losses.BatchAllTripletLoss(model = model,margin=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encode(data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "warmup_steps = int(len(loader) * epochs * 0.1)\n",
    "model.fit(train_objectives=[(loader, loss)],\n",
    "          \n",
    "          epochs = epochs,\n",
    "          warmup_steps = warmup_steps,\n",
    "          output_path='./triple_loss_all_1000'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator = TripletEvaluator.from_input_examples(test_set, name=\"trec-test\")\n",
    "model.evaluate(test_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'tripleloss_all_1000_1_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('/kaggle/input/dataset/translated_full')\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data_test = pd.read_csv('/kaggle/input/dataset/testing.txt')\n",
    "data_test = data_test.drop_duplicates()\n",
    "data_test = data_test.reset_index(drop =True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=data['Category'].unique().tolist()\n",
    "nb_classes = len(classes)\n",
    "print(nb_classes)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,type_c in enumerate(classes):\n",
    "   for j,type_t in enumerate(data['Category']):\n",
    "       if type_c == type_t :\n",
    "           data.loc[j,'Category'] = i\n",
    "for i,type_c in enumerate(classes):\n",
    "   for j,type_t in enumerate(data_test['Category']):\n",
    "       if type_c == type_t :\n",
    "           data_test.loc[j,'Category'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['embeddings'] = data['text'].apply(model.encode)\n",
    "data_test['embeddings'] = data_test['text'].apply(model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = data['embeddings'].to_list()\n",
    "y_train = data['Category'].to_list()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)\n",
    "X_test = data_test['embeddings'].to_list()\n",
    "y_test = data_test['Category'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clfs = [\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=3000,\n",
    "                                              class_weight='balanced')\n",
    "    ),\n",
    "    ('RandomForest', RandomForestClassifier(max_depth=18,\n",
    "                                            n_estimators=75,\n",
    "                                            random_state=0)\n",
    "    ),\n",
    "    ('KNN 5', KNeighborsClassifier(n_neighbors=4)\n",
    "    ),\n",
    "    ('SVM C1', SVC(C=1,\n",
    "                   class_weight='balanced')\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "def print_val_scores(scores: list[float]) -> None:\n",
    "\n",
    "  print(f'Cross validation scores: mean: {np.mean(scores):.3f}, '\n",
    "        f'all: {[round(score, 3) for score in scores]}')\n",
    "\n",
    "\n",
    "def print_stratified_kfold(clfs: list[tuple[str, any]], X_train: pd.DataFrame,\n",
    "                           y_train: pd.Series, n_splits: int = 5, cv: int = 5,\n",
    "                           ) -> None:\n",
    "\n",
    "  for clf in clfs:\n",
    "    print(f'\\nStratifiedKFold - classifier: {clf[0]}:\\n')\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    scores = cross_val_score(clf[1],\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            cv=cv)\n",
    "\n",
    "    print_val_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stratified_kfold(clfs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "clf =  SVC(C=1,class_weight='balanced')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# prob = clf.predict_proba(X_test)\n",
    "# print(prob)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.title(f'SVM - acc {accuracy:.3f}', size=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
