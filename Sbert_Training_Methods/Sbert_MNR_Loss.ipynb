{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "snli = datasets.load_dataset('snli', split='train')\n",
    "\n",
    "snli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli = datasets.load_dataset('glue', 'mnli', split = 'train')\n",
    "mnli = mnli.remove_columns(['idx'])\n",
    "mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.concatenate_datasets([snli,mnli])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: False if x['label'] != 0 else True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    " \n",
    "\n",
    "train_samples = []\n",
    "for row in dataset:\n",
    "    train_samples.append(InputExample(texts=[row['premise'],row['hypothesis']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import datasets\n",
    "\n",
    "batch_size = 16\n",
    "loader = datasets.NoDuplicatesDataLoader(train_samples , batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import models,SentenceTransformer\n",
    "\n",
    "bert = models.Transformer('')\n",
    "pooler = models.Pooling(bert.get_word_embedding_dimension(),pooling_mode_mean_tokens = True)\n",
    "\n",
    "model = SentenceTransformer(modules=[bert,pooler])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "loss = losses.MultipleNegativesRankingLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "warmup_steps = int(len(loader) * epochs * 0.1)\n",
    "model.fit(train_objectives=[(loader, loss)],\n",
    "          \n",
    "          epochs = epochs,\n",
    "          warmup_steps = warmup_steps,\n",
    "      \n",
    "          output_path='./MNR_biobert_snli_mnli'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_pickle('')\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data_test = pd.read_csv('')\n",
    "data_test = data_test.drop_duplicates()\n",
    "data_test = data_test.reset_index(drop =True)\n",
    "classes=data['Category'].unique().tolist()\n",
    "nb_classes = len(classes)\n",
    "print(nb_classes)\n",
    "print(classes)\n",
    "for i,type_c in enumerate(classes):\n",
    "   for j,type_t in enumerate(data['Category']):\n",
    "       if type_c == type_t :\n",
    "           data.loc[j,'Category'] = i\n",
    "for i,type_c in enumerate(classes):\n",
    "   for j,type_t in enumerate(data_test['Category']):\n",
    "       if type_c == type_t :\n",
    "           data_test.loc[j,'Category'] = i\n",
    "data['embeddings'] = data['text'].apply(model.encode)\n",
    "data_test['embeddings'] = data_test['text'].apply(model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = data['embeddings'].to_list()\n",
    "y_train = data['Category'].to_list()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)\n",
    "X_test = data_test['embeddings'].to_list()\n",
    "y_test = data_test['Category'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clfs = [\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=3000,\n",
    "                                              class_weight='balanced')\n",
    "    ),\n",
    "    ('RandomForest', RandomForestClassifier(max_depth=18,\n",
    "                                            n_estimators=75,\n",
    "                                            random_state=0)\n",
    "    ),\n",
    "    ('KNN 5', KNeighborsClassifier(n_neighbors=4)\n",
    "    ),\n",
    "    ('SVM C1', SVC(C=1,\n",
    "                   class_weight='balanced')\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "def print_val_scores(scores: list[float]) -> None:\n",
    "\n",
    "  print(f'Cross validation scores: mean: {np.mean(scores):.3f}, '\n",
    "        f'all: {[round(score, 3) for score in scores]}')\n",
    "\n",
    "\n",
    "def print_stratified_kfold(clfs: list[tuple[str, any]], X_train: pd.DataFrame,\n",
    "                           y_train: pd.Series, n_splits: int = 5, cv: int = 5,\n",
    "                           ) -> None:\n",
    "\n",
    "  for clf in clfs:\n",
    "    print(f'\\nStratifiedKFold - classifier: {clf[0]}:\\n')\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    scores = cross_val_score(clf[1],\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            cv=cv)\n",
    "\n",
    "    print_val_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stratified_kfold(clfs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "clf =  SVC(C=1,\n",
    "                   class_weight='balanced')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# prob = clf.predict_proba(X_test)\n",
    "# print(prob)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.title(f'SVM - acc {accuracy:.3f}', size=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
